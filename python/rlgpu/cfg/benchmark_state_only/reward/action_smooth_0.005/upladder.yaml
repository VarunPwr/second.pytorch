env:
  numEnvs: 512
  envSpacing: 4.  # [m]
  command: "vel"
  commandChangeStep: 500
  risk_reward: False
  rush_reward: False
  vel_reward_exp_coeff: 0.25
  terrain:
    terrain_name: "upladder" #  # none, plane or trimesh
    curriculum: true
    texture: "none"
    static_friction: 1.0  # [-]
    dynamic_friction: 1.0  # [-]
    restitution: 0.        # [-]
    # terrain types: [smooth slope, rough slope, stairs up, stairs down, discrete]
    robot_origin: [-2.5, 0, 0]
    terrain_origin: [0., 0., 0.]

  asset:
    penalize_contacts_on: []
    terminate_after_contacts_on: ["trunk", "upper"]
  vision:
    get_image: False
    image_type: "depth" # depth, rgb, rgbd
    frame_stack: 4
    update_freq: 4 # how many control steps do we update the image buffer
    width: 64
    height: 64

  plane:
    staticFriction: 10.0  # [-]
    dynamicFriction: 10.0  # [-]
    restitution: 0.        # [-]

  baseInitState:
    pos: [0.0, 0.0, 0.32] # x,y,z [m]
    rot: [0.0, 0.0, 0.0, 1.0] # x,y,z,w [quat]
    vLinear: [0.0, 0.0, 0.0]  # x,y,z [m/s]
    vAngular: [0.0, 0.0, 0.0]  # x,y,z [rad/s]

  randomCommandRanges:
    linear_x: [0.5, 0.51] # min max [m/s]
    linear_y: [0., 0.]   # min max [m/s]
    yaw: [0., 0.]             # min max [rad/s]

  control:
    # PD Drive parameters:
    stiffness: 20.0  # [N*m/rad]
    damping: 0.4    # [N*m*s/rad]
    actionScale: 0.5
    hipActionScale: 0.15
    controlFrequencyInv: 4  # 60 Hz

  defaultJointAngles:  # = target angles when action = 0.0
    FL_upper: 0.9    # [rad]
    RL_upper: 0.9    # [rad]
    FR_upper: 0.9   # [rad]
    RR_upper: 0.9   # [rad]

    FL_hip: 0.     # [rad]
    RL_hip: 0.     # [rad]
    FR_hip: 0.     # [rad]
    RR_hip: 0.     # [rad]

    FL_lower: -1.8     # [rad]
    RL_lower: -1.8     # [rad]
    FR_lower: -1.8     # [rad]
    RR_lower: -1.8     # [rad]
    
  urdfAsset:
    collapseFixedJoints: True
    fixBaseLink: False
    defaultDofDriveMode: 1 # see GymDofDriveModeFlags (0 is none, 1 is pos tgt, 2 is vel tgt, 4 effort)

  learn:
    # rewards
    soft_limits:
      soft_dof_pos_limit: 1.
      soft_dof_vel_limit: 0.9
      soft_torque_limit: 1.
    linearVelocityXYRewardScale: 2.0
    angularVelocityZRewardScale: 1.0
    linearVelocityZRewardScale: -0.2
    torqueRewardScale: -0.000025 
    actionSmoothingRewardScale: -0.005 
    stumble: 0.
    feet_air_time: 0.
    dof_vel_limit: -0.002
    torque_limit: -0.00002
    collision: -1

    # normalization
    linearVelocityScale: 2.0
    angularVelocityScale: 0.25
    dofPositionScale: 1.0
    dofVelocityScale: 0.05

    # episode length in seconds
    episodeLength_s: 50

    # use diagonal action
    diagonal_act: False

  # viewer cam:
  viewer:
    refEnv: 0
    pos: [-4, 0., 1.2]  # [m]
    # pos: [-2, 0.3, 0.4]  # [m]
    # pos: [0, 0, 0.3]  # [m]
    lookat: [0.2, 0.2, -0.3]  # [m]

  controller: False

  # sensor:
  sensor:
    historical_step: 4
    sys_id: False

sim:
  substeps: 2
  gravity: [0., 0. ,-9.81]  # [m/s^2]
  up_axis: 1  # 0 is y, 1 is z
  dt: 0.005

  physx:
    num_threads: 8
    solver_type: 1  # 0: pgs, 1: tgs
    num_position_iterations: 4
    num_velocity_iterations: 0
    contact_offset: 0.01
    rest_offset: 0.0
    bounce_threshold_velocity: 0.2
    max_depenetration_velocity: 5.0

task:
  randomize: True
  randomization_params:
    frequency: 10000
    observations:
      range: [0, .002] # range for the white noise
      range_correlated: [0, .001 ] # range for correlated noise, refreshed with freq `frequency`
      operation: "additive"
      distribution: "gaussian"
      schedule: "linear"   # "constant" is to turn on noise after `schedule_steps` num steps
      schedule_steps: 40000
    actor_params:
      a1:
        rigid_body_properties:
          mass: 
            range: [0.8, 1.2]
            operation: "scaling"
            distribution: "uniform"
            schedule: "linear"  
            schedule_steps: 30000
        rigid_shape_properties:
          friction: 
            num_buckets: 250
            range: [0.7, 1.3]
            operation: "scaling"
            distribution: "uniform"

randomize_reward:
  randomize: False
  randomization_params:
    frequency: 100000
    reward_scale:
      linearVelocityXYRewardScale:
        range: [1., 3.]
        distribution: "uniform"
        schedule: "linear"
        schedule_steps: 50000
      angularVelocityZRewardScale:
        range: [1., 2.]
        distribution: "uniform"
        schedule: "linear"
        schedule_steps: 50000
      torqueRewardScale:
        range: [-0.000005, -0.000035]
        distribution: "uniform"
        schedule: "linear"
        schedule_steps: 50000
      actionSmoothingRewardScale:
        range: [-0.000015, -0.000025]
        distribution: "uniform"
        schedule: "linear"
        schedule_steps: 50000